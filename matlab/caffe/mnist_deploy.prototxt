name: "mnist"
input: "data"
input_dim: 10
input_dim: 1
input_dim: 28
input_dim: 28
# ------------------------ layer 1 -----------------------------
layers {
 layer {
   name: "conv1"
   type: "conv"
   num_output: 12
   kernelsize: 5
   pad: 2
   stride: 1
   weight_filler {
     type: "gaussian"
     std: 0.0001
   }   
   bias_filler {
     type: "constant"
   }   
   blobs_lr: 1.
   blobs_lr: 2.
 }
 bottom: "data"
 top: "conv1"
}
layers {
 layer {
   name: "pool1"
   type: "pool"
   kernelsize: 3
   stride: 2
   pool: MAX 
 }
 bottom: "conv1"
 top: "pool1"
}
layers {
 layer {
   name: "relu1"
   type: "relu"
 }
 bottom: "pool1"
 top: "pool1"
}
layers {
  layer {
    name: "norm1"
    type: "lrn"
    local_size: 3
    alpha: 0.00005
    beta: 0.75
  }
  bottom: "pool1"
  top: "norm1"
}
# --------------------------- layer 2 ------------------------
layers {
 layer {
   name: "conv2"
   type: "conv"
   num_output: 12
   kernelsize: 5
   pad: 2
   stride: 1
   weight_filler {
     type: "gaussian"
     std: 0.01
   }
   bias_filler {
     type: "constant"
   }
   blobs_lr: 1.
   blobs_lr: 2.
 }
 bottom: "norm1"
 top: "conv2"
}
layers {
 layer {
   name: "relu2"
   type: "relu"
 }
 bottom: "conv2"
 top: "conv2"
}
layers {
 layer {
   name: "pool2"
   type: "pool"
   kernelsize: 3
   stride: 2
   pool: AVE
 }
 bottom: "conv2"
 top: "pool2"
}
layers {
  layer {
    name: "norm2"
    type: "lrn"
    local_size: 3
    alpha: 0.00005
    beta: 0.75
  }
  bottom: "pool2"
  top: "norm2"
}
#--------------------------layer 3------------------------
layers {
 layer {
   name: "ip1"
   type: "innerproduct"
   num_output: 10
   weight_filler {
     type: "gaussian"
     std: 0.01
   }
   bias_filler {
     type: "constant"
   }
   blobs_lr: 1.
   blobs_lr: 2.
   weight_decay: 250.
   weight_decay: 0.
 }
 bottom: "norm2"
 top: "ip1"
}
#-----------------------output------------------------
layers {
 layer {
   name: "prob"
   type: "softmax"
 }
 bottom: "ip1"
 top: "prob"
}
